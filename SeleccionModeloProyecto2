
import pandas as pd
import numpy as np

from ucimlrepo import fetch_ucirepo

# fetch dataset
predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)

# data (as pandas dataframes)
X = predict_students_dropout_and_academic_success.data.features
y = predict_students_dropout_and_academic_success.data.targets

# metadata
print(predict_students_dropout_and_academic_success.metadata)

# variable information
print(predict_students_dropout_and_academic_success.variables)



#Discretizar variable objetivo
#Correlacion con variable objetivo
#Graduate = 2
#Enrolled = 1
#Dropout= 0
def ponerNumerico(row):
    if row["Target"] == 'Dropout':
        row["TargetN"] = 0

    elif row["Target"] == 'Graduate':
        row["TargetN"] = 2
    else:
        row["TargetN"] = 1
    return row

y = y.apply(ponerNumerico ,axis = 1)

#Discretizar porcentaje examenes aprobados
# 0- no presento examenes
#1- [0%-25%)
#2- 25%-50%
# 50%-75%
#75%-100%
def discretizar_porcentajeExamenesAprobados(row):
    if row['Curricular units 1st sem (evaluations)']==0:
        row["% of approved evaluations 1st sem"] = 0
    else:
        porcentaje = row['Curricular units 1st sem (approved)']/row['Curricular units 1st sem (evaluations)']
        if porcentaje >= 0.75:
            row["% of approved evaluations 1st sem"] = 4
        elif porcentaje >= 0.50:
            row["% of approved evaluations 1st sem"] = 3
        elif porcentaje >= 0.25:
            row["% of approved evaluations 1st sem"] = 2
        else:
            row["% of approved evaluations 1st sem"] = 1

    if row['Curricular units 2nd sem (evaluations)']==0:
        row["% of approved evaluations 2nd sem"] = 0
    else:
        porcentaje = row['Curricular units 2nd sem (approved)']/row['Curricular units 2nd sem (evaluations)']
        if porcentaje >= 0.75:
            row["% of approved evaluations 2nd sem"] = 4
        elif porcentaje >= 0.50:
            row["% of approved evaluations 2nd sem"] = 3
        elif porcentaje >= 0.25:
            row["% of approved evaluations 2nd sem"] = 2
        else:
            row["% of approved evaluations 2nd sem"] = 1

    return row

X = X.apply(discretizar_porcentajeExamenesAprobados ,axis = 1)

# 0- 95-120
# 1- 120-160
# 2- 160-200

def discretizar_resultados_examenes(row):
  if row["Previous qualification (grade)"]>= 160:
    row["Previous qualification (grade) performance"] = 2

  elif row["Previous qualification (grade)"]>= 120 :
    row["Previous qualification (grade) performance"] = 1

  else:
    row["Previous qualification (grade) performance"] = 0

  if row["Admission grade"]>= 160:
    row["Admission grade performance"] = 2

  elif row["Admission grade"]>= 120 :
    row["Admission grade performance"] = 1

  else:
    row["Admission grade performance"] = 0

  return row

X = X.apply(discretizar_resultados_examenes, axis = 1)



X.head()

def discretizar_nota_semestre(row):
  if row['Curricular units 1st sem (grade)'] >= X['Curricular units 1st sem (grade)'].quantile(0.75):
    row["Grade sem1"] = 4
  elif row['Curricular units 1st sem (grade)'] >= X['Curricular units 1st sem (grade)'].quantile(0.50):
    row["Grade sem1"] = 3
  elif row['Curricular units 1st sem (grade)'] >= X['Curricular units 1st sem (grade)'].quantile(0.25):
    row["Grade sem1"] = 2
  else:
    row["Grade sem1"] = 1

  if row['Curricular units 2nd sem (grade)'] >= X['Curricular units 2nd sem (grade)'].quantile(0.75):
    row["Grade sem2"] = 4
  elif row['Curricular units 2nd sem (grade)'] >= X['Curricular units 2nd sem (grade)'].quantile(0.50):
    row["Grade sem2"] = 3
  elif row['Curricular units 2nd sem (grade)'] >= X['Curricular units 2nd sem (grade)'].quantile(0.25):
    row["Grade sem2"] = 2
  else:
    row["Grade sem2"] = 1

  return row

X = X.apply(discretizar_nota_semestre,axis = 1)

Variables = ['Marital Status', "Previous qualification", "Scholarship holder",  'Tuition fees up to date', 'Gender',
'Previous qualification (grade) performance', 'Admission grade performance',"Mother's occupation","Father's occupation" , 'Age at enrollment',"Grade sem1","Grade sem2"]

df = X[Variables]
df['Target'] = y['TargetN']

df.head()

# Estimacion construccion modelo PC
from pgmpy.estimators import PC
est = PC(data=df)

estimated_model = est.estimate(variant="stable", max_cond_vars=4)
print(estimated_model)
print(estimated_model.nodes())
print(estimated_model.edges())

#Estimacion CPDS modelo construido con PC
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

estimated_model = BayesianNetwork(estimated_model)

"""##Estimando la estructura de un modelo a partir de datos: puntajes"""

#Metodo Hill Climb por K2

from pgmpy.estimators import HillClimbSearch
from pgmpy.estimators import K2Score
from pgmpy.models import BayesianNetwork

scoring_method = K2Score(data=df)

esth = HillClimbSearch(data=df)

estimated_modelHC1 = esth.estimate(
    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)
)
print(estimated_modelHC1)
print(estimated_modelHC1.nodes())
print(estimated_modelHC1.edges())
estimated_modelHC1 = BayesianNetwork(estimated_modelHC1.edges())

print(type(estimated_modelHC1))

#Puntaje K2
print(scoring_method.score(estimated_modelHC1))

#Metodo Hill Clim por Bic
from pgmpy.estimators import BicScore

scoring_method = BicScore(data=df)
esth = HillClimbSearch(data=df)
estimated_modelHC2 = esth.estimate(
    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)
)
print(estimated_modelHC2)
print(estimated_modelHC2.nodes())
print(estimated_modelHC2.edges())
estimated_modelHC2 = BayesianNetwork(estimated_modelHC2.edges())

#Puntaje BIC
print(scoring_method.score(estimated_modelHC2))

#Medidas de desempeño: 1. BIC, 2. K2 , 3. ROC 4, Matriz confusion
from pgmpy.estimators import BicScore
from pgmpy.estimators import K2Score
from sklearn.metrics import roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score

from pgmpy.models import BayesianNetwork
from pgmpy.factors.discrete import TabularCPD
import scipy
from sklearn.model_selection import train_test_split
import pyparsing
import torch
import statsmodels
import tqdm
import joblib

train,test = train_test_split(df, test_size = 0.2, random_state= 42)
test.drop([2269,505,1532,949,3281],inplace=True,axis=0)

from pgmpy.inference import VariableElimination
from pgmpy.estimators import BicScore

#Infer PC
estimated_model.fit( data = train , estimator = MaximumLikelihoodEstimator)

bic_score = BicScore(train)
# Calcula el BIC


bic_value = bic_score.score(estimated_model)
infer_PC = VariableElimination(estimated_model)

bic_value

from pgmpy.estimators import ParameterEstimator
# Estimar parámetros utilizando MaximumLikelihoodEstimator
estimated_modelHC1.fit( data = train , estimator = MaximumLikelihoodEstimator)
infer_HC1 = VariableElimination(estimated_modelHC1)

bic_score = BicScore(train)
# Calcula el BIC
bic_value = bic_score.score(estimated_modelHC1)
print(scoring_method.score(estimated_modelHC1))

bic_value



estimated_modelHC2.fit( data = train , estimator = MaximumLikelihoodEstimator)
infer_HC2 = VariableElimination(estimated_modelHC2)
resultados_HC2 =[]
bic_score = BicScore(train)
# Calcula el BIC
bic_value = bic_score.score(estimated_modelHC2)

bic_value

from sklearn.metrics import accuracy_score, confusion_matrix, recall_score,ConfusionMatrixDisplay

#Inferencia PC
resultadosPC = []
probasPC = []

for index,row in test.iterrows():
    variables = ['Marital Status', 'Age at enrollment', 'Previous qualification (grade) performance', 'Gender', 'Admission grade performance', "Father's occupation", 'Scholarship holder', 'Previous qualification', 'Grade sem1', 'Grade sem2', 'Tuition fees up to date', "Mother's occupation"]
    evidencia={}
    for variable in Variables:
      evidencia[variable]= row[variable]
    inferencia = infer_PC.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosPC.append(target)
    probasPC.append(proba)

# METRICAS PC
import matplotlib.pyplot as plt


accuracy = accuracy_score(test["Target"],resultadosPC)
matriz = confusion_matrix(test["Target"],resultadosPC)
# Calcular el recall para cada clase individualmente
recall_clase_0 = recall_score(test["Target"],resultadosPC ,labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosPC , labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosPC , labels=[2], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.show()

recall_clase_2

#Inferencia HC1
resultadosHC1 = []
probasHC1 = []

for index,row in test.iterrows():
    variables = ['Marital Status', 'Age at enrollment', 'Previous qualification (grade) performance', 'Gender', 'Admission grade performance', "Father's occupation", 'Scholarship holder', 'Previous qualification', 'Grade sem1', 'Grade sem2', 'Tuition fees up to date', "Mother's occupation"]
    evidencia={}
    for variable in Variables:
      evidencia[variable]= row[variable]
    inferencia = infer_HC1.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosHC1.append(target)
    probasHC1.append(proba)

import matplotlib.pyplot as plt

accuracy = accuracy_score(test["Target"],resultadosHC1)
matriz = confusion_matrix(test["Target"],resultadosHC1)
recall_clase_0 = recall_score(test["Target"],resultadosHC1, labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosHC1, labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosHC1, labels=[2], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.show()

recall_clase_2

#Inferencia HC2
resultadosHC2 = []
probasHC2 = []

for index,row in test.iterrows():
    Variables = ['Scholarship holder', 'Gender', 'Marital Status', 'Previous qualification', 'Previous qualification (grade) performance', 'Admission grade performance', 'Grade sem1', 'Grade sem2', 'Tuition fees up to date']
    evidencia={}
    for variable in Variables:
      evidencia[variable]= row[variable]
    inferencia = infer_HC2.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosHC2.append(target)
    probasHC2.append(proba)

accuracy = accuracy_score(test["Target"],resultadosHC2)
matriz = confusion_matrix(test["Target"],resultadosHC2)
recall_clase_0 = recall_score(test["Target"],resultadosHC2, labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosHC2, labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosHC2, labels=[2], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.show()

recall_clase_2

from sklearn.metrics import accuracy_score, confusion_matrix

accuracy = accuracy_score(test["Target"],resultados)

matriz = confusion_matrix(test["Target"],resultados)
accuracy
