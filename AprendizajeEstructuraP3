# ANALISIS EXPLORATORIO 
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("DatosValle4000.csv")


#Limpiar base de datos--------------------------------------------------------------------------------------------------------------------
df.dropna(inplace = True)
df = df[df["periodo"] >= 20221]
df= df[df['fami_estratovivienda'].str.contains("Estrato")]
df.drop(['cole_depto_ubicacion','estu_depto_presentacion' ], axis = 1, inplace= True)
df.sort_values(by = ["fami_estratovivienda","desemp_ingles"], ascending = True, inplace = True)

cuantil1 = df["punt_global"].quantile(0.4)
cuantil2 = df["punt_global"].quantile(0.8)

#Grupo1 0-212
#Grupo2 212-
#Grupo4 287-337
#Grupo5 337-

dfN = pd.DataFrame()

etiquetas= []
for columna in df.columns[0:-1]:
    if columna == "periodo":
       dfN[columna]= df[columna]
    else:
        dfN[columna] = pd.factorize(df[columna])[0]
    
    valor = 0
    dicc = {}
    for categoria in df[columna].unique():
        dicc[categoria]= valor
        valor +=1 
    etiquetas.append(dicc)
        
def ponerNumerico(row):
    if row["punt_global"] >= cuantil2:
        row["TargetN"] = 2
    elif row["punt_global"] >= cuantil1:
        row["TargetN"] = 1
    else :
          row["TargetN"] = 0
    return row

df = df.apply(ponerNumerico,axis = 1)

dfN["Target"] = df["TargetN"]

#Analisis estadistico de correlaciones--------------------------------------------------------------------------------------------------------------------------
import scipy.stats as stats

# Crear una matriz vacía para almacenar las correlaciones
matriz_correlaciones = pd.DataFrame(np.zeros((len(dfN.columns[1:]), len(dfN.columns[1:]))))
matriz_correlaciones.columns = dfN.columns[1:]
matriz_correlaciones.index = dfN.columns[1:]
matriz_pvalores = matriz_correlaciones

# Calcular las correlaciones de Kendall y completar la matriz
for variable1 in dfN.columns[1:]:
    for variable2 in dfN.columns[1:]:
        coeficiente_tau, p_valor = stats.kendalltau(dfN[variable1], dfN[variable2])
        matriz_correlaciones.loc[variable1, variable2] = coeficiente_tau
        matriz_pvalores.loc[variable1, variable2] = p_valor

# Mostrar la matriz de correlaciones
matriz_correlaciones


#Aprendizaje de estructura------------------------------------------------------------------------------------------

from pgmpy.estimators import PC
from pgmpy.estimators import HillClimbSearch
from pgmpy.estimators import K2Score
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.estimators import BicScore
from pgmpy.models import BayesianNetwork
from pgmpy.factors.discrete import TabularCPD
from pgmpy.inference import VariableElimination
import scipy
from sklearn.model_selection import train_test_split
import pyparsing
import torch
import statsmodels
import tqdm
import joblib
from sklearn.metrics import roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import ConfusionMatrixDisplay
from pgmpy.estimators import ParameterEstimator

dfNdef = dfN[['cole_area_ubicacion', 'cole_bilingue', 'cole_caracter',
       'cole_calendario', 'cole_genero', 'cole_jornada', 'cole_naturaleza',
       'estu_genero', 'fami_estratovivienda', 'fami_tienecomputador',
       'fami_tieneinternet', 'desemp_ingles','Target']]

train,test = train_test_split(dfNdef, test_size = 0.2, random_state= 42, stratify = dfNdef["Target"])


#Algortimo PC------------------------------------------------------------------------------------

est = PC(data=train)
estimated_modelPC = est.estimate(variant="stable", max_cond_vars=4)

print(estimated_modelPC)
print(estimated_modelPC.nodes())
print(estimated_modelPC.edges())



estimated_modelPC = BayesianNetwork(estimated_modelPC)
estimated_modelPC.fit( data = train , estimator = MaximumLikelihoodEstimator)

bic_score = BicScore(train)
bic_value = bic_score.score(estimated_modelPC)

infer_PC = VariableElimination(estimated_modelPC)


#Inferencia PC
resultadosPC = []
probasPC = []

for index,row in test.iterrows():
    variables = []
    for variable in  list(estimated_modelPC.nodes()):
        if variable != 'Target':
           variables.append(variable)
    evidencia={}
    for variable in variables:
      evidencia[variable]= row[variable]
    inferencia = infer_PC.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosPC.append(target)
    probasPC.append(proba)

# METRICAS PC
import matplotlib.pyplot as plt


accuracyPC = accuracy_score(test["Target"],resultadosPC)
matriz = confusion_matrix(test["Target"],resultadosPC)
# Calcular el recall para cada clase individualmente
recall_clase_0 = recall_score(test["Target"],resultadosPC ,labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosPC , labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosPC , labels=[2], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.title("Matriz de PC")
plt.show()


#Algoritmo Hill Climb calibrado con K2 -------------------------------------------------------------------------------------------
scoring_method = K2Score(data=train)
esth = HillClimbSearch(data=train)

estimated_modelHC1 = esth.estimate(
    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)
)
print(estimated_modelHC1)
print(estimated_modelHC1.nodes())
print(estimated_modelHC1.edges())
estimated_modelHC1 = BayesianNetwork(estimated_modelHC1.edges())

#Puntaje K2
print(scoring_method.score(estimated_modelHC1))

# Estimar parámetros utilizando MaximumLikelihoodEstimator
estimated_modelHC1.fit( data = train , estimator = MaximumLikelihoodEstimator)
infer_HC1 = VariableElimination(estimated_modelHC1)

bic_score = BicScore(train)
# Calcula el BIC
bic_value = bic_score.score(estimated_modelHC1)
print(scoring_method.score(estimated_modelHC1))

#Inferencia HC1
resultadosHC1 = []
probasHC1 = []

for index,row in test.iterrows():
    variables = []
    for variable in  list(estimated_modelHC1.nodes()):
        if variable != 'Target':
           variables.append(variable)
    
    evidencia={}
    for variable in variables:
      evidencia[variable]= row[variable]
    inferencia = infer_HC1.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosHC1.append(target)
    probasHC1.append(proba)
    
import matplotlib.pyplot as plt

accuracyHC1 = accuracy_score(test["Target"],resultadosHC1)
matriz = confusion_matrix(test["Target"],resultadosHC1)
recall_clase_0 = recall_score(test["Target"],resultadosHC1, labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosHC1, labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosHC1, labels=[2], average='micro')
recall_clase_3 = recall_score(test["Target"],resultadosHC1, labels=[3], average='micro')
recall_clase_4 = recall_score(test["Target"],resultadosHC1, labels=[4], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.title("Matriz de hill climb con k2")
plt.show()

#Hill Climb con BIC -------------------------------------------------------------------------------
scoring_method = BicScore(data=train)
esth = HillClimbSearch(data=train)
estimated_modelHC2 = esth.estimate(
    scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)
)
print(estimated_modelHC2)
print(estimated_modelHC2.nodes())
print(estimated_modelHC2.edges())
estimated_modelHC2 = BayesianNetwork(estimated_modelHC2.edges())
print(scoring_method.score(estimated_modelHC2))


estimated_modelHC2.fit( data = train , estimator = MaximumLikelihoodEstimator)
infer_HC2 = VariableElimination(estimated_modelHC2)
resultados_HC2 =[]
bic_score = BicScore(train)
# Calcula el BIC
bic_value = bic_score.score(estimated_modelHC2)

#Inferencia HC2
resultadosHC2 = []
probasHC2 = []

for index,row in test.iterrows():
    
    variables = []
    for variable in  list(estimated_modelHC2.nodes()):
        if variable != 'Target':
           variables.append(variable)
    evidencia={}
    
    for variable in variables:
      evidencia[variable]= row[variable]
    inferencia = infer_HC2.query(["Target"], evidence=evidencia)
    valores = list(inferencia.values)
    target = valores.index(max(valores))
    proba= max(valores)
    resultadosHC2.append(target)
    probasHC2.append(proba)
    
accuracyHC2 = accuracy_score(test["Target"],resultadosHC2)
matriz = confusion_matrix(test["Target"],resultadosHC2)
recall_clase_0 = recall_score(test["Target"],resultadosHC2, labels=[0], average='micro')
recall_clase_1 = recall_score(test["Target"],resultadosHC2, labels=[1], average='micro')
recall_clase_2 = recall_score(test["Target"],resultadosHC2, labels=[2], average='micro')
disp = ConfusionMatrixDisplay(confusion_matrix=matriz)
disp.plot()
plt.title("Matriz de hill climb con bic")
plt.show()


